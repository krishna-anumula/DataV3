{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from itertools import compress\n",
    "import en_core_web_lg\n",
    "nlp_spacy = en_core_web_lg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('output_combined.tsv',delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('article_data_V2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1088, 7)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1 = data_1.truncate(after=1087)\n",
    "data_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "505it [00:00, 21396.05it/s]\n",
      "1088it [00:00, 29708.11it/s]\n"
     ]
    }
   ],
   "source": [
    "snippets_list = []\n",
    "for idx, row in tqdm(data.iterrows()):\n",
    "        temp_dict = dict()\n",
    "        temp_dict['title'] = row['title']\n",
    "        temp_dict['url'] = row['url']\n",
    "        temp_dict['body'] = row['body']\n",
    "        temp_dict['company_name'] = row['company_name']\n",
    "        snippets_list.append(temp_dict)\n",
    "for idx, row in tqdm(data_1.iterrows()):\n",
    "        temp_dict = dict()\n",
    "        temp_dict['title'] = row['title']\n",
    "        temp_dict['url'] = row['url']\n",
    "        temp_dict['body'] = row['data']\n",
    "        temp_dict['company_name'] = row['company_name']\n",
    "        snippets_list.append(temp_dict)\n",
    "\n",
    "data_new = pd.DataFrame(snippets_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1593, 4), Index(['title', 'url', 'body', 'company_name'], dtype='object'))"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.shape, data_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           Intellectual Property Rights During -- and Aft...\n",
       "url             https:\\/\\/www.mddionline.com\\/legal\\/intellect...\n",
       "body            Manufacturers came to the rescue to quickly de...\n",
       "company_name                                   ford_motor_company\n",
       "Name: 1592, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.to_csv(\"data_bef_prep.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aft_prep = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'text', 'article_id', 'company_name', 'title', 'id'], dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_aft_prep.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_list = ['alphabet','google','facebook','ITV','Pearson','BT group','BT','Vodafone group','vodafone','burberry group','burberry','nike','nike inc','compass group',\n",
    "'restaurant group','trg','amazon','amazon in','booking holdings','kingfisher','marks and spencer group','marks and spencer','marks & spencer group','marks & spencer',\n",
    "'next plc','tjx','tjx companies','sainsbury','tesco','british american tobacco','coca-cola','coca cola','diageo','imperial brands','pepsico',\n",
    "'PHILIP MORRIS INTERNATIONAL','philip morris','TATE AND LYLE','TATE & LYLE','PROCTER & GAMBLE','PROCTER and GAMBLE','p&g','RECKITT BENCKISER GROUP','RECKITT BENCKISER',\n",
    "'RECKITT','RB','unilever','BAKER HUGHES','BP','CABOT OIL & GAS CORP','coterra energy','CHEVRON CORP','CHEVRON','EOG RESOURCES','eog','EXXON MOBIL','EXXONMOBIL',\n",
    "'HALLIBURTON','PHILLIPS','PIONEER NATURAL RESOURCE','PIONEER NATURAL RESOURCES','VALERO ENERGY','VALERO','BANK OF AMERICA','BARCLAYS','CITIGROUP','CITI',\n",
    "'FIRST REPUBLIC BANK','FIRST REPUBLIC','JPMORGAN CHASE','JPMORGAN','JP MORGAN','J.P. MORGAN','LLOYDS BANKING GROUP','LLOYDS BANK','NATWEST GROUP','NATWEST',\n",
    "'STANDARD CHARTERED','STANDARD CHARTERED PLC','WELLS FARGO','3I GROUP','3I','AMERICAN EXPRESS','BERKSHIRE HATHAWAY INC','BERKSHIRE HATHAWAY','BERKSHIRE',\n",
    "'HATHAWAY','CME GROUP','HARGREAVES LANSDOWN','LONDON STOCK EXCHANGE GROUP','LSEG','LONDON STOCK EXCHANGE','AVIVA','DIRECT LINE INSURANCE','DIRECT LINE group',\n",
    "'DIRECT LINE','LEGAL AND GENERAL GROUP','LEGAL AND GENERAL','legal & general','PHOENIX GROUP','phoenix','PROGRESSIVE CORP','PROGRESSIVE CORPORATION','PROGRESSIVE','PRUDENTIAL','ANTHEM',\n",
    "'BOSTON SCIENTIFIC','CONVATEC GROUP','CONVATEC','DANAHER CORPORATION','DANAHER CORP','DANAHER','SMITH AND NEPHEW','SMITH & NEPHEW','ASTRAZENECA','GLAXOSMITHKLINE',\n",
    "'GSK','ILLUMINA','JOHNSON & JOHNSON',\"JOHNSON's\",'J&J','THERMO FISHER SCIENTIFIC','THERMO FISHER','ASHTEAD GROUP','ASHTEAD','BAE SYSTEMS','BUNZL','ELECTROCOMPONENTS',\n",
    "'FERGUSON PLC','FERGUSON','IMI PLC','IMI','MELROSE INDUSTRIES','MELROSE','QINETIQ GROUP','QINETIQ','RAYTHEON TECHNOLOGIES','RAYTHEON','SMITHS GROUP','SMITHS',\n",
    "'HAYS PLC','HAYS','IHS MARKIT','RELX group','RELX','RENTOKIL INITIAL','RENTOKIL','SERCO GROUP','SERCO','FIRSTGROUP','GO-AHEAD GROUP','GO-AHEAD','ROYAL MAIL group',\n",
    "'ROYAL MAIL','ADVANCED MICRO DEVICES','AMD','QORVO','TEXAS INSTRUMENT','TEXAS INSTRUMENTS','ADOBE','ATLASSIAN','ATLASSIAN CORPORATION','AVEVA GROUP','AVEVA',\n",
    "'CAPITA GROUP','CAPITA','CTS','Cognizant','FDM GROUP HOLDINGS','FDM GROUP','FDM','FIDELITY NATIONAL INFORMATION SERVICES','FNI Services','GODADDY','INTUIT',\n",
    "'MASTERCARD','MICROSOFT CORP','MICROSOFT CORPORATION','MICROSOFT','OKTA','PAYCHEX','PAYPAL','SNOWFLAKE','SS AND C TECHNOLOGIES','SS&C TECHNOLOGIES','SS&C',\n",
    "'VISA INC','VISA','ZOOM VIDEO COMMUNICATIONS','ZOOM VIDEO','ZOOM COMMUNICATIONS','AMPHENOL CORP','AMPHENOL CORPORATION','AMPHENOL','CDW','CISCO SYSTEMS','CISCO',\n",
    "'HP','Hewlett-Packard','MOTOROLA SOLUTIONS','MOTOROLA','QUALCOMM','SPIRENT COMMUNICATIONS','SPIRENT','ANGLO AMERICAN','BHP GROUP','BHP','CRODA INTERNATIONAL','CRODA',\n",
    "'ESSENTRA','INTERNATIONAL FLAVORS & FRAGRANCES','IFF','JOHNSON MATTHEY','JMAT','MARTIN MARIETTA MATERIALS INC','MARTIN MARIETTA MATERIALS','MONDI','MONDI GROUP',\n",
    "'NEWMONT','NEWMONT CORPORATION','SMITH (DS)','DS Smith','ASSURA REIT','ASSURA FINANCING','ASSURA','CAPITAL & COUNTIES PROPERTIES','CAPITAL & COUNTIES','CROWN CASTLE',\n",
    "'CROWN CASTLE INTERNATIONAL CORP','CROWN CASTLE INTERNATIONAL CORPORATION','EQUINIX REIT','EQUINIX','EQUITY LIFESTYLE PROPERTIES','ELS','LAND SECURITIES GROUP',\n",
    "'LANDSEC','LONDONMETRIC PROPERTY','LMP','SBA COMMUNICATIONS','SBA COMMUNICATIONS CORPORATION','SBAC','SEGRO PLC','SEGRO','SHAFTESBURY PLC','SHAFTESBURY',\n",
    "'SUN COMMUNITIES','AMERICAN ELECTRIC POWER','american electric','AEP','CENTRICA','EXELON CORPORATION','EXELON','NATIONAL GRID','NEXTERA ENERGY','NEXTERA','PUBLIC SERVICE ENTERPRISE GROUP',\n",
    "'PSEG','UNITED UTILITIES GROUP','UNITED UTILITIES','WEC ENERGY GROUP','WEC ENERGY','SSE PLC','GENERAL MOTORS','LEAR CORPORATION','LEAR','LEAR CORP','STARBUCKS',\n",
    "'EBAY','TESLA INC','TESLA',\"MCDONALD'S CORP\",\"MCDONALD'S\",'WALMART','WALMART CORPORATE','COLGATE-PALMOLIVE','COLGATE','3M','3M SCIENCE','ROLLS-ROYCE HOLDINGS','ROLLS-ROYCE',\n",
    "'EQUIFAX','FEDEX CORP','FEDEX CORPORATION','FEDEX','UBER TECHNOLOGIES','UBER','GENERAL ELECTRIC','GE','LOCKHEED MARTIN CORPORATION','LOCKHEED MARTIN','NVIDIA CORPORATION',\n",
    "'NVIDIA','APPLE INC','APPLE','XCEL ENERGY','AUTOHOME','BAIDU','KAKAKU','NETEASE','NINTENDO','NINTENDO LTD','NIPPON TELEVISION','NIPPON TV','TENCENT HOLDINGS',\n",
    "'TENCENT','BHARTI AIRTEL','AIRTEL','KDDI CORP','KDDI CORPORATION','KDDI','NIPPON TELEGRAPH AND TELEPHONE CORPORATION','NTT CORP','SOFTBANK CORP','SOFTBANK GROUP',\n",
    "'SOFTBANK','AISIN CORP','AISIN','BRIDGESTONE CORPORATION','BRIDGESTONE GROUP','BRIDGESTONE','DONGFENG MOTOR GROUP','HONDA MOTOR COMPANY','HONDA','ISUZU MOTORS LTD',\n",
    "'ISUZU MOTORS','ISUZU','MAHINDRA AND MAHINDRA LTD','MAHINDRA & MAHINDRA LTD','MAHINDRA & MAHINDRA','Mahindra GROUP','SUBARU CORP','SUBARU CORPORATION','SUBARU',\n",
    "'SUMITOMO ELECTRIC INDUSTRIES','SUMITOMO ELECTRIC','SUZUKI MOTOR CORP','SUZUKI MOTOR CORPORATION','SUZUKI MOTOR','SUZUKI','TATA MOTORS LTD','TATA MOTORS',\n",
    "'TOYOTA MOTOR CORP','TOYOTA MOTOR CORPORATION','TOYOTA','XPENG INC','XPENG INC.','XPENG','YAMAHA MOTOR COMPANY','YAMAHA MOTORS','YAMAHA','YAMAHA MOTOR CO., LTD.',\n",
    "'YAMAHA MOTOR','PARKER-HANNIFIN CORP','PARKER-HANNIFIN','PARKER HANNIFIN','Nestlé India','Nestlé','Nestle','PFIZER INC','PFIZER','msci','msci inc','salesforce','itochu',\n",
    "'komatsu','airbnb','sage','expedia','bajaj finance','twilio','whitbread','otis','japan tobacco','daifuku','ACCIONA','ALDI','AMP Capital','ASDA','AXA','Actelion','Air Liquide','Aramco','Aurora Cannabis','Aviva','AVIVA PLC','Bank Hapoalim BM','BestBuy','Biffa','Big Society Capital','Blackrock','Boeing','British Airways','Cambridge Glasshouse Company','Castrol','credit Suisse','DWS','Deutsche Bank','Dewan Housing Finance Corporation Ltd','Discovery Limited','Dove','Drax','E.ON','ESSECO','Eastman Kodak','Enel','Eni','FMC','Flipkart','Ford', 'Ford Motor Company','Freedom Foods Group Ltd', 'GM+Shell','Generali','Goldman Sachs','Granville','H&M','HAZAMA ANDO CORP','HS2','Hanson','Heathrow','Heineken','ICICI Bank','ING','Infosys','Jhonson Controls','John Lewis','KLM Airlines','KPMG','Kao data','Kobe Steel','Konkola Copper Mines','LG Polymers','LeasePlan','Lego','Lombard Odier','Luckin','Luckin Coffee Inc', 'Mars','Mercedes Benz','Metlife','Monzo Bank', 'Morrisons','Anglo American','Salzgitter','Arrival','First Bus','EIB','Enel','Flynn','Primark','Shell', 'Rolls-Royce', 'Tevva', 'Vattenfall','Violia','Carbon Clean','Nishimatsu Construction Co., Ltd.', 'Nokia','O2', 'OVO Energy','Polestar','SQUAD','Stena Bulk', 'Takeda', 'Target','Toshiba IT-Services Corp', 'Total','Turing Pharma','Valeant Pharma','Yes Bank Limited','Zhenhua','abu_dhabi_national_oil_company','agricultural bank of china','alibaba', 'Alibaba Group Holding Limited', 'Alibaba Group Holding', 'Alibaba.com','alibaba_group',]\n",
    "\n",
    "\n",
    "comp_list = [each_string.lower() for each_string in comp_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ent_org(text):\n",
    "        lst=[]\n",
    "        doc = nlp_spacy(text)\n",
    "        for word in doc.ents:\n",
    "            if(word.label_=='ORG'):\n",
    "                low_txt = word.text.lower()\n",
    "                lst.append(low_txt)\n",
    "        return lst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_comp_title(snippet_company,title_company):\n",
    "    snippet_company = snippet_company[:-1]\n",
    "    comp_lst=snippet_company.split(\",\")\n",
    "    \n",
    "    if(all(elem == comp_lst[0] for elem in comp_lst) and comp_lst[0]==title_company):     #all the companies found in snippet level are belonging to company found at article\n",
    "        return '4-1',title_company\n",
    "    \n",
    "    elif(any(map(lambda v: v in title_company.split(\",\"), comp_lst))):              #any one of the companies found in snippet level are belonging to company found at article\n",
    "        return '4-2',title_company\n",
    "    \n",
    "    else:                                                                           #company found at snippet level are not belonging to company found at article\n",
    "        return '4-3','None'\n",
    "\n",
    "def mul_comp_title(snippet_company,title_company):\n",
    "    snippet_company = snippet_company[:-1]\n",
    "    comp_lst=snippet_company.split(\",\")\n",
    "    \n",
    "    if(all(elem == comp_lst[0] for elem in comp_lst) and any(map(lambda v: v in title_company.split(\",\"), comp_lst))):      #all the companies found in snippet level are belonging to any one of the company found at article\n",
    "        return '7-1',snippet_company.split(\",\")[0]\n",
    "    \n",
    "    elif(any(map(lambda v: v in title_company.split(\",\"), comp_lst))):                                                      #any one of the companies in snippet level are belonging to any one of the company found at article\n",
    "        lst = list(map(lambda v: v in title_company.split(\",\"), comp_lst))\n",
    "        return '7-2',','. join(set(compress(comp_lst, lst)))\n",
    "    \n",
    "    else:                                                                                                                   #company found at snippet level are not belonging to any company found at article\n",
    "        return '7-3','None'\n",
    "\n",
    "\n",
    "def tag(snippet,title):\n",
    "    k=0\n",
    "    #title = title\n",
    "    #snippet = data_list[id-(key*15)+1]\n",
    "    title_company=\"\"\n",
    "    snippet_company=\"\"\n",
    "\n",
    "    lst_art = ent_org(title) #get ORG tagged texts for Article title\n",
    "    lst_snip = ent_org(snippet) #get ORG tagged texts for snippets\n",
    "\n",
    "    for company in comp_list:          #Check for ORG texts in master list\n",
    "        if(company.lower() in lst_art):\n",
    "            k=1\n",
    "            title_company=title_company+company+\",\"\n",
    "        if(company.lower() in lst_snip):\n",
    "            snippet_company=snippet_company+company+\",\"\n",
    "\n",
    "    #Code for the snippets, where article title do not have company name\n",
    "    if(k==0):\n",
    "        \n",
    "        snippet_company = snippet_company[:-1]\n",
    "        \n",
    "        if not snippet_company:     #Getting coref data, since snippet don't have any company\n",
    "            return '1',\"coref\",\"None\"\n",
    "        else:                                          #having company in snippet\n",
    "            return '3',snippet_company,\"None\"\n",
    "        \n",
    "    #Code for the snippets, where article title have company name\n",
    "    else:\n",
    "        title_company = title_company[:-1]\n",
    "\n",
    "        if(len(title_company.split(\",\"))==1):       #Article title having single company\n",
    "            \n",
    "            if(snippet_company):                    #snippet having company name\n",
    "                snippet_company = snippet_company[:-1]\n",
    "                comp_lst=snippet_company.split(\",\")\n",
    "                \n",
    "                if(all(elem == comp_lst[0] for elem in comp_lst) and comp_lst[0]==title_company):     #all the companies found in snippet level are belonging to company found at article\n",
    "                    return '4-1',title_company,title_company\n",
    "                \n",
    "                elif(any(map(lambda v: v in title_company.split(\",\"), comp_lst))):              #any one of the companies found in snippet level are belonging to company found at article\n",
    "                    return '4-2',title_company,title_company\n",
    "                \n",
    "                else:                                                                           #company found at snippet level are not belonging to company found at article\n",
    "                    return '4-3','None',title_company\n",
    "                #return one_comp_title(snippet_company,title_company),title_company\n",
    "\n",
    "            else:\n",
    "                return '6',title_company,title_company\n",
    "        \n",
    "        else:                                       #Article title having multiple companies\n",
    "        \n",
    "            if(snippet_company):                     #Snippet have company name\n",
    "                snippet_company = snippet_company[:-1]\n",
    "                comp_lst=snippet_company.split(\",\")\n",
    "                \n",
    "                if(all(elem == comp_lst[0] for elem in comp_lst) and any(map(lambda v: v in title_company.split(\",\"), comp_lst))):      #all the companies found in snippet level are belonging to any one of the company found at article\n",
    "                    return '7-1',snippet_company.split(\",\")[0],title_company\n",
    "                \n",
    "                elif(any(map(lambda v: v in title_company.split(\",\"), comp_lst))):                                                      #any one of the companies in snippet level are belonging to any one of the company found at article\n",
    "                    lst = list(map(lambda v: v in title_company.split(\",\"), comp_lst))\n",
    "                    return '7-2',','. join(set(compress(comp_lst, lst))),title_company\n",
    "                \n",
    "                else:                                                                                                                   #company found at snippet level are not belonging to any company found at article\n",
    "                    return '7-3','None',title_company\n",
    "                #return mul_comp_title(snippet_company,title_company),title_company\n",
    "\n",
    "            else:\n",
    "                return '9',title_company,title_company\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_aft_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64138it [10:58, 97.40it/s] \n"
     ]
    }
   ],
   "source": [
    "no_tit_no_snip=0\n",
    "no_tit=0\n",
    "no_tit_snip=0\n",
    "sin_tit_no_snip=0\n",
    "yes_tit=0\n",
    "sin_tit=0\n",
    "mul_tit_no_snip=0\n",
    "mul_tit=0\n",
    "sin_tit_all_snip=0\n",
    "sin_tit_any_snip=0\n",
    "sin_tit_oth_snip=0\n",
    "mul_tit_all_snip=0\n",
    "mul_tit_any_snip=0\n",
    "mul_tit_oth_snip=0\n",
    "final_snippend_list=[]\n",
    "\n",
    "for idx, row in tqdm(data_aft_prep.iterrows()):\n",
    "    if(str(row['text'])!='nan' and str(row['title'])!='nan'):\n",
    "        value,snippet_org, title_org = tag(row['text'],row['title'])\n",
    "    else:\n",
    "        value='nan'\n",
    "        snippet_org='nan'\n",
    "        title_org='nan'\n",
    "    temp_dict=dict()\n",
    "    temp_dict['article_id'] = row['article_id']\n",
    "    temp_dict['title'] = row['title']\n",
    "    temp_dict['snippet'] = row['text']\n",
    "    temp_dict['company_name'] = row['company_name']\n",
    "    #temp_dict['snippet_coref'] = coref\n",
    "    temp_dict['snippet_org'] = snippet_org\n",
    "    #temp_dict['snippet_coref_org'] = snippet_coref_org\n",
    "    temp_dict['title_org'] = title_org\n",
    "    if(snippet_org == title_org):\n",
    "        temp_dict['tit_sni_same'] = 1\n",
    "    else:\n",
    "        temp_dict['tit_sni_same'] = 0\n",
    "    #temp_dict['coref_tit_sni_same'] = bool2\n",
    "    temp_dict['id'] = row['id']\n",
    "    temp_dict['value'] = value\n",
    "    if(value == '1'):\n",
    "        no_tit_no_snip+=1\n",
    "        no_tit+=1\n",
    "    elif(value == '3'):\n",
    "        no_tit_snip+=1\n",
    "        no_tit+=1\n",
    "    elif(value == '6'):\n",
    "        sin_tit_no_snip+=1\n",
    "        yes_tit+=1\n",
    "        sin_tit+=1\n",
    "    elif(value == '9'):\n",
    "        mul_tit_no_snip+=1\n",
    "        yes_tit+=1\n",
    "        mul_tit+=1\n",
    "    elif(value == '4-1'):\n",
    "        sin_tit_all_snip+=1\n",
    "        yes_tit+=1\n",
    "        sin_tit+=1\n",
    "    elif(value == '4-2'):\n",
    "        sin_tit_any_snip+=1\n",
    "        yes_tit+=1\n",
    "        sin_tit+=1\n",
    "    elif(value == '4-3'):\n",
    "        sin_tit_oth_snip+=1\n",
    "        yes_tit+=1\n",
    "        sin_tit+=1\n",
    "    elif(value == '7-1'):\n",
    "        mul_tit_all_snip+=1\n",
    "        yes_tit+=1\n",
    "        mul_tit+=1\n",
    "    elif(value == '7-2'):\n",
    "        mul_tit_any_snip+=1\n",
    "        yes_tit+=1\n",
    "        mul_tit+=1\n",
    "    elif(value == '7-3'):\n",
    "        mul_tit_oth_snip+=1\n",
    "        yes_tit+=1\n",
    "        mul_tit+=1\n",
    "    \n",
    "    final_snippend_list.append(temp_dict)\n",
    "snippet_df = pd.DataFrame(final_snippend_list) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df.to_csv(\"emperical_result.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of sentences :  64138\n",
      "10700\n",
      "\n",
      "Percentage of sentences with company in title : 16.68%\n",
      "\n",
      "53400\n",
      "\n",
      "Percentage of sentences with no company in title : 83.26%\n",
      "\n",
      "9533\n",
      "\n",
      "Percentage of sentences with single company in title : 14.86%\n",
      "\n",
      "1167\n",
      "\n",
      "Percentage of sentences with multiple companies in title : 1.82%\n",
      "\n",
      "50561\n",
      "\n",
      "Percentage of sentences with no company in title as well as snippet : 78.83%\n",
      "\n",
      "2839\n",
      "\n",
      "Percentage of sentences with no company in title and company in snippet : 4.43%\n",
      "\n",
      "7173\n",
      "\n",
      "Percentage of sentences with single company in title and no company in snippet : 11.18%\n",
      "\n",
      "2071\n",
      "\n",
      "Percentage of sentences with single company in title and snippet have title company : 3.23%\n",
      "\n",
      "83\n",
      "\n",
      "Percentage of sentences with single company in title and one of the companies in snippet is title company : 0.13%\n",
      "\n",
      "206\n",
      "\n",
      "Percentage of sentences with single company in title and snippet company is not matching title company : 0.32%\n",
      "\n",
      "973\n",
      "\n",
      "Percentage of sentences with multiple companies in title and no company in snippet : 1.52%\n",
      "\n",
      "126\n",
      "\n",
      "Percentage of sentences with multiple companies in title and snippet having one of the company in title : 0.2%\n",
      "\n",
      "32\n",
      "\n",
      "Percentage of sentences with multiple companies in title and any one of the companies in snippet is same as one of the title company : 0.05%\n",
      "\n",
      "36\n",
      "\n",
      "Percentage of sentences with multiple companies in title and snippet company is matching none of the title company : 0.06%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Total no of sentences : \",len(data_aft_prep))\n",
    "print(yes_tit)\n",
    "print()\n",
    "print(\"Percentage of sentences with company in title : \"+str(round((yes_tit/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(no_tit)\n",
    "print()\n",
    "print(\"Percentage of sentences with no company in title : \"+str(round((no_tit/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(sin_tit)\n",
    "print()\n",
    "print(\"Percentage of sentences with single company in title : \"+str(round((sin_tit/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(mul_tit)\n",
    "print()\n",
    "print(\"Percentage of sentences with multiple companies in title : \"+str(round((mul_tit/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(no_tit_no_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with no company in title as well as snippet : \"+str(round((no_tit_no_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(no_tit_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with no company in title and company in snippet : \"+str(round((no_tit_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(sin_tit_no_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with single company in title and no company in snippet : \"+str(round((sin_tit_no_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(sin_tit_all_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with single company in title and snippet have title company : \"+str(round((sin_tit_all_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(sin_tit_any_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with single company in title and one of the companies in snippet is title company : \"+str(round((sin_tit_any_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(sin_tit_oth_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with single company in title and snippet company is not matching title company : \"+str(round((sin_tit_oth_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(mul_tit_no_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with multiple companies in title and no company in snippet : \"+str(round((mul_tit_no_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(mul_tit_all_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with multiple companies in title and snippet having one of the company in title : \"+str(round((mul_tit_all_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(mul_tit_any_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with multiple companies in title and any one of the companies in snippet is same as one of the title company : \"+str(round((mul_tit_any_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()\n",
    "print(mul_tit_oth_snip)\n",
    "print()\n",
    "print(\"Percentage of sentences with multiple companies in title and snippet company is matching none of the title company : \"+str(round((mul_tit_oth_snip/len(data_aft_prep))*100,2))+\"%\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('trainV3.csv')\n",
    "data_dev = pd.read_csv('devV3.csv')\n",
    "data_test = pd.read_csv('testV3.csv')\n",
    "data_aug = pd.read_csv('total_aug_data.csv')\n",
    "data_trainaug = pd.read_csv('trainPaugV3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2083, 12), (412, 12), (462, 12), (4904, 15), (6977, 14))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape, data_dev.shape, data_test.shape, data_aug.shape, data_trainaug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['index', 'doccano_auto_id', 'article_id', 'prev_id', 'company_name',\n",
       "        'article_title', 'text', 'ESG_label', 'difficulty', 'doccano_label',\n",
       "        'sub_category', 'version'],\n",
       "       dtype='object'),\n",
       " Index(['index', 'doccano_auto_id', 'article_id', 'prev_id', 'company_name',\n",
       "        'article_title', 'text', 'ESG_label', 'difficulty', 'doccano_label',\n",
       "        'sub_category', 'version'],\n",
       "       dtype='object'),\n",
       " Index(['index', 'doccano_auto_id', 'article_id', 'prev_id', 'company_name',\n",
       "        'article_title', 'text', 'ESG_label', 'difficulty', 'doccano_label',\n",
       "        'sub_category', 'version'],\n",
       "       dtype='object'),\n",
       " Index(['index', 'doccano_auto_id', 'article_id', 'prev_id', 'company_name',\n",
       "        'article_title', 'text', 'ESG_label', 'difficulty', 'doccano_label',\n",
       "        'sub_category', 'version', 'aug_type', 'ID_val', 'delete'],\n",
       "       dtype='object'),\n",
       " Index(['index', 'doccano_auto_id', 'article_id', 'prev_id', 'company_name',\n",
       "        'article_title', 'text', 'ESG_label', 'difficulty', 'doccano_label',\n",
       "        'sub_category', 'version', 'ID_val', 'is_aug'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns, data_dev.columns, data_test.columns, data_aug.columns, data_trainaug.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/n12844/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stb(df):\n",
    "    \n",
    "    df = df.drop_duplicates('title')\n",
    "    df = df.drop_duplicates('body')\n",
    "    df['article_id'] = range(0, len(df))\n",
    "    df = df.sort_values('title')\n",
    "    df = df.sort_values('article_id')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new2 = delete_stb(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2208, 9)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>rel</th>\n",
       "      <th>hit_count</th>\n",
       "      <th>probable_esg_type</th>\n",
       "      <th>company_name</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>Fracking machinery at a site operated by Range...</td>\n",
       "      <td>228</td>\n",
       "      <td>9</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-26</td>\n",
       "      <td>OTIS WORLDWIDE CORP (OTIS) Q1 2021 Earnings Ca...</td>\n",
       "      <td>https://www.fool.com/earnings/call-transcripts...</td>\n",
       "      <td>Good morning, and welcome to Otis's First Quar...</td>\n",
       "      <td>162</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-01</td>\n",
       "      <td>OTIS WORLDWIDE CORP (OTIS) Q4 2020 Earnings Ca...</td>\n",
       "      <td>https://www.fool.com/earnings/call-transcripts...</td>\n",
       "      <td>Good morning and welcome to Otis Fourth Quarte...</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>﻿ Otis Unveils New Generation of Digitally Nat...</td>\n",
       "      <td>https://www.intellasia.net/%EF%BB%BFotis-unvei...</td>\n",
       "      <td>- Gen3 elevator adds built-in IoT benefits to ...</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>Otis Unveils New Generation of Digitally Nativ...</td>\n",
       "      <td>https://www.intellasia.net/otis-unveils-new-ge...</td>\n",
       "      <td>- Gen3 elevator adds built-in IoT benefits to ...</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-06-08</td>\n",
       "      <td>Otis Worldwide : Unveils New Generation of Dig...</td>\n",
       "      <td>https://www.marketscreener.com//quote/stock/OT...</td>\n",
       "      <td>FARMINGTON, Conn., June 8, 2021 /PRNewswire/ -...</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2021-02-20</td>\n",
       "      <td>Central Maine business briefs: OTIS Federal Cr...</td>\n",
       "      <td>https://www.centralmaine.com/2021/02/20/centra...</td>\n",
       "      <td>JAY -- OTIS Federal Credit Union raised a tota...</td>\n",
       "      <td>52</td>\n",
       "      <td>4</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-05-24</td>\n",
       "      <td>Otis College of Art and Design's Fashion Thesi...</td>\n",
       "      <td>https://wwd.com/fashion-news/fashion-features/...</td>\n",
       "      <td>Students graduating from the fashion program a...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-29</td>\n",
       "      <td>Today in History: Aretha Franklin's cover of O...</td>\n",
       "      <td>https://santamariatimes.com/lifestyles/today-i...</td>\n",
       "      <td>Today is Thursday, April 29, the 119th day of ...</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2021-08-23</td>\n",
       "      <td>Why Supermodel Carré Otis Is Taking on This To...</td>\n",
       "      <td>https://www.thedailybeast.com/supermodel-carre...</td>\n",
       "      <td>Carré Otis wants justice, but she also wants c...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>all</td>\n",
       "      <td>otis</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                              title  \\\n",
       "0   2021-03-30  Joseph Otis Minott: Biden must prioritize heal...   \n",
       "1   2021-04-26  OTIS WORLDWIDE CORP (OTIS) Q1 2021 Earnings Ca...   \n",
       "2   2021-02-01  OTIS WORLDWIDE CORP (OTIS) Q4 2020 Earnings Ca...   \n",
       "3   2021-06-08  ﻿ Otis Unveils New Generation of Digitally Nat...   \n",
       "4   2021-06-08  Otis Unveils New Generation of Digitally Nativ...   \n",
       "6   2021-06-08  Otis Worldwide : Unveils New Generation of Dig...   \n",
       "7   2021-02-20  Central Maine business briefs: OTIS Federal Cr...   \n",
       "8   2021-05-24  Otis College of Art and Design's Fashion Thesi...   \n",
       "9   2021-04-29  Today in History: Aretha Franklin's cover of O...   \n",
       "10  2021-08-23  Why Supermodel Carré Otis Is Taking on This To...   \n",
       "\n",
       "                                                  url  \\\n",
       "0   https://triblive.com/opinion/joseph-otis-minot...   \n",
       "1   https://www.fool.com/earnings/call-transcripts...   \n",
       "2   https://www.fool.com/earnings/call-transcripts...   \n",
       "3   https://www.intellasia.net/%EF%BB%BFotis-unvei...   \n",
       "4   https://www.intellasia.net/otis-unveils-new-ge...   \n",
       "6   https://www.marketscreener.com//quote/stock/OT...   \n",
       "7   https://www.centralmaine.com/2021/02/20/centra...   \n",
       "8   https://wwd.com/fashion-news/fashion-features/...   \n",
       "9   https://santamariatimes.com/lifestyles/today-i...   \n",
       "10  https://www.thedailybeast.com/supermodel-carre...   \n",
       "\n",
       "                                                 body  rel  hit_count  \\\n",
       "0   Fracking machinery at a site operated by Range...  228          9   \n",
       "1   Good morning, and welcome to Otis's First Quar...  162          1   \n",
       "2   Good morning and welcome to Otis Fourth Quarte...  136          1   \n",
       "3   - Gen3 elevator adds built-in IoT benefits to ...   78          1   \n",
       "4   - Gen3 elevator adds built-in IoT benefits to ...   78          1   \n",
       "6   FARMINGTON, Conn., June 8, 2021 /PRNewswire/ -...   78          1   \n",
       "7   JAY -- OTIS Federal Credit Union raised a tota...   52          4   \n",
       "8   Students graduating from the fashion program a...   27          2   \n",
       "9   Today is Thursday, April 29, the 119th day of ...   27          2   \n",
       "10  Carré Otis wants justice, but she also wants c...    2          2   \n",
       "\n",
       "   probable_esg_type company_name  article_id  \n",
       "0                all         otis           0  \n",
       "1                all         otis           1  \n",
       "2                all         otis           2  \n",
       "3                all         otis           3  \n",
       "4                all         otis           4  \n",
       "6                all         otis           5  \n",
       "7                all         otis           6  \n",
       "8                all         otis           7  \n",
       "9                all         otis           8  \n",
       "10               all         otis           9  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_new2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_cleaned_text(text):\n",
    "    text = re.sub(\"\\(.*?\\)\", '', text)\n",
    "    text = re.sub(\"\\[.*?\\]\", '', text)\n",
    "    text = re.sub('\\*', '', text)\n",
    "    text = re.sub('\\s\\s+', ' ', text)\n",
    "    text = re.sub('\\.\\s\\.', '.', text)\n",
    "    text = re.sub(',\\s,', ',', text)\n",
    "    text = re.sub(';\\s;', ';', text)\n",
    "    text = re.sub(':\\s:', ':', text)\n",
    "    text = re.sub('\\?\\s\\?', '?', text)\n",
    "    text = re.sub('\\!\\s\\!', '!', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_sents_for_doc(text):\n",
    "    text = get_cleaned_text(text)\n",
    "    sents = nltk.tokenize.sent_tokenize(str(text))\n",
    "    len_sents = len(sents)\n",
    "    final_2sents_list = []\n",
    "    for i in range(1, len_sents):\n",
    "        temp_text = sents[i-1] + ' ' + sents[i]\n",
    "        temp_text = re.sub('\"', '', temp_text)\n",
    "        final_2sents_list.append(temp_text.strip())\n",
    "    return final_2sents_list\n",
    "\n",
    "def map_snippets_art(row):\n",
    "    body = row['body']\n",
    "    snippets = get_sents_for_doc(body)\n",
    "    final_snippend_list = []\n",
    "    for snip in snippets:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['text'] = snip\n",
    "        temp_dict['article_id'] = row['article_id']\n",
    "        temp_dict['url'] = row['url']\n",
    "        temp_dict['company_name'] = row['company_name']\n",
    "        temp_dict['title'] = row['title']\n",
    "        final_snippend_list.append(temp_dict)\n",
    "    return final_snippend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_snippets(art_df, start_snippet_id):\n",
    "    snippets_list = []\n",
    "    for idx, row in tqdm(art_df.iterrows()):\n",
    "        one_snippet_list = map_snippets_art(row)\n",
    "        snippets_list.extend(one_snippet_list)\n",
    "    snippet_df = pd.DataFrame(snippets_list)\n",
    "    snippet_df['id'] = range(start_snippet_id, len(snippet_df))\n",
    "    return snippet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_list = []\n",
    "lst=[]\n",
    "for idx, row in data_new2.iterrows():\n",
    "    lst.append(idx)\n",
    "    one_snippet_list = map_snippets_art(row)\n",
    "    snippets_list.extend(one_snippet_list)\n",
    "snippet_df = pd.DataFrame(snippets_list)\n",
    "snippet_df['id'] = range(0, len(snippet_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(snippet_df.id)\n",
    "#id_list=lst\n",
    "for i in range(1,len(id_list)):\n",
    "    if(id_list[i]-id_list[i-1]!=1):\n",
    "        print(id_list[i],id_list[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df.to_csv('snippets_bytitle_V1_NLTK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fracking machinery at a site operated by Range...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The U.S. Environmental Protection Agency is on...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Next month, Sen. Martin Heinrich, D-N.M., will...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was the first ever federal standard for m...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We need President Biden and EPA Administrator ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  article_id  \\\n",
       "0  Fracking machinery at a site operated by Range...           0   \n",
       "1  The U.S. Environmental Protection Agency is on...           0   \n",
       "2  Next month, Sen. Martin Heinrich, D-N.M., will...           0   \n",
       "3  This was the first ever federal standard for m...           0   \n",
       "4  We need President Biden and EPA Administrator ...           0   \n",
       "\n",
       "                                                 url company_name  \\\n",
       "0  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "1  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "2  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "3  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "4  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "\n",
       "                                               title  id  \n",
       "0  Joseph Otis Minott: Biden must prioritize heal...   0  \n",
       "1  Joseph Otis Minott: Biden must prioritize heal...   1  \n",
       "2  Joseph Otis Minott: Biden must prioritize heal...   2  \n",
       "3  Joseph Otis Minott: Biden must prioritize heal...   3  \n",
       "4  Joseph Otis Minott: Biden must prioritize heal...   4  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new2.to_csv('data_bytitle_V2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4133/764195945.py:1: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  snippet_df = snippet_df.drop('id', 1)\n"
     ]
    }
   ],
   "source": [
    "snippet_df = snippet_df.drop('id', 1)\n",
    "snippet_df = snippet_df.sort_values('text')\n",
    "snippet_df = snippet_df.drop_duplicates('text')\n",
    "snippet_df = snippet_df.sort_values('article_id')\n",
    "snippet_df['id'] = range(0, len(snippet_df))\n",
    "snippet_df = snippet_df.sort_values('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(snippet_df.id)\n",
    "#id_list=lst\n",
    "for i in range(1,len(id_list)):\n",
    "    if(id_list[i]-id_list[i-1]!=1):\n",
    "        print(id_list[i],id_list[i-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>If we are to meet Biden's goal of a 100% clean...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Wind and solar must be the centerpieces of Bid...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>When methane is emitted from the oil and gas i...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Since every step in the oil and gas production...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This includes aggressively expanding renewable...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text  article_id  \\\n",
       "20  If we are to meet Biden's goal of a 100% clean...           0   \n",
       "30  Wind and solar must be the centerpieces of Bid...           0   \n",
       "12  When methane is emitted from the oil and gas i...           0   \n",
       "18  Since every step in the oil and gas production...           0   \n",
       "21  This includes aggressively expanding renewable...           0   \n",
       "\n",
       "                                                  url company_name  \\\n",
       "20  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "30  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "12  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "18  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "21  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "\n",
       "                                                title  id  \n",
       "20  Joseph Otis Minott: Biden must prioritize heal...   0  \n",
       "30  Joseph Otis Minott: Biden must prioritize heal...   1  \n",
       "12  Joseph Otis Minott: Biden must prioritize heal...   2  \n",
       "18  Joseph Otis Minott: Biden must prioritize heal...   3  \n",
       "21  Joseph Otis Minott: Biden must prioritize heal...   4  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'article_id', 'url', 'company_name', 'title', 'id'], dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df.to_csv('snippets_bytitle_V1_after_DupRem_NLTK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_cleaned_text(text):\n",
    "    text = re.sub(\"\\(.*?\\)\", '', text)\n",
    "    text = re.sub(\"\\[.*?\\]\", '', text)\n",
    "    text = re.sub('\\*', '', text)\n",
    "    text = re.sub('\\s\\s+', ' ', text)\n",
    "    text = re.sub('\\.\\s\\.', '.', text)\n",
    "    text = re.sub(',\\s,', ',', text)\n",
    "    text = re.sub(';\\s;', ';', text)\n",
    "    text = re.sub(':\\s:', ':', text)\n",
    "    text = re.sub('\\?\\s\\?', '?', text)\n",
    "    text = re.sub('\\!\\s\\!', '!', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_sents_for_doc(text):\n",
    "    text = get_cleaned_text(text)\n",
    "    #doc = nlp_spacy(text)\n",
    "    #sents = list(doc.sents)\n",
    "    sents = nltk.tokenize.sent_tokenize(str(text))\n",
    "    len_sents = len(sents)\n",
    "    final_1sents_list = []\n",
    "    for i in range(0, len_sents):\n",
    "        temp_text = sents[i]\n",
    "        temp_text = re.sub('\"', '', temp_text)\n",
    "        final_1sents_list.append(temp_text.strip())\n",
    "    return final_1sents_list\n",
    "\n",
    "def map_snippets_art(row):\n",
    "    body = row['body']\n",
    "    snippets = get_sents_for_doc(body)\n",
    "    final_snippend_list = []\n",
    "    for snip in snippets:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['text'] = snip\n",
    "        temp_dict['article_id'] = row['article_id']\n",
    "        temp_dict['url'] = row['url']\n",
    "        temp_dict['company_name'] = row['company_name']\n",
    "        temp_dict['title'] = row['title']\n",
    "        final_snippend_list.append(temp_dict)\n",
    "    return final_snippend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99302, 5)\n",
      "(98374, 5)\n"
     ]
    }
   ],
   "source": [
    "snippets_list = []\n",
    "lst=[]\n",
    "for idx, row in data_new2.iterrows():\n",
    "    lst.append(idx)\n",
    "    one_snippet_list = map_snippets_art(row)\n",
    "    snippets_list.extend(one_snippet_list)\n",
    "snippet_df = pd.DataFrame(snippets_list)\n",
    "#snippet_df = snippet_df.drop('id', 1)\n",
    "#snippet_df = snippet_df.sort_values('text')\n",
    "print(snippet_df.shape)\n",
    "snippet_df = snippet_df.drop_duplicates(['text','article_id'])\n",
    "snipper_df = snippet_df.sort_values('article_id')\n",
    "print(snippet_df.shape)\n",
    "#snippet_df['id'] = range(0, len(snippet_df))\n",
    "#snippet_df = snippet_df.sort_values('id')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fracking machinery at a site operated by Range...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The U.S. Environmental Protection Agency is on...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Next month, Sen. Martin Heinrich, D-N.M., will...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This was the first ever federal standard for m...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We need President Biden and EPA Administrator ...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  article_id  \\\n",
       "0  Fracking machinery at a site operated by Range...           0   \n",
       "1  The U.S. Environmental Protection Agency is on...           0   \n",
       "2  Next month, Sen. Martin Heinrich, D-N.M., will...           0   \n",
       "3  This was the first ever federal standard for m...           0   \n",
       "4  We need President Biden and EPA Administrator ...           0   \n",
       "\n",
       "                                                 url company_name  \\\n",
       "0  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "1  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "2  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "3  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "4  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "\n",
       "                                               title  \n",
       "0  Joseph Otis Minott: Biden must prioritize heal...  \n",
       "1  Joseph Otis Minott: Biden must prioritize heal...  \n",
       "2  Joseph Otis Minott: Biden must prioritize heal...  \n",
       "3  Joseph Otis Minott: Biden must prioritize heal...  \n",
       "4  Joseph Otis Minott: Biden must prioritize heal...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snippet_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>article_id</th>\n",
       "      <th>url</th>\n",
       "      <th>company_name</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fracking machinery at a site operated by Range...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://triblive.com/opinion/joseph-otis-minot...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Joseph Otis Minott: Biden must prioritize heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good morning, and welcome to Otis's First Quar...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.fool.com/earnings/call-transcripts...</td>\n",
       "      <td>otis</td>\n",
       "      <td>OTIS WORLDWIDE CORP (OTIS) Q1 2021 Earnings Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good morning and welcome to Otis Fourth Quarte...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://www.fool.com/earnings/call-transcripts...</td>\n",
       "      <td>otis</td>\n",
       "      <td>OTIS WORLDWIDE CORP (OTIS) Q4 2020 Earnings Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>- Gen3 elevator adds built-in IoT benefits to ...</td>\n",
       "      <td>3</td>\n",
       "      <td>https://www.intellasia.net/%EF%BB%BFotis-unvei...</td>\n",
       "      <td>otis</td>\n",
       "      <td>﻿ Otis Unveils New Generation of Digitally Nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>- Gen3 elevator adds built-in IoT benefits to ...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://www.intellasia.net/otis-unveils-new-ge...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Otis Unveils New Generation of Digitally Nativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>FARMINGTON, Conn., June 8, 2021 /PRNewswire/ -...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://www.marketscreener.com//quote/stock/OT...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Otis Worldwide : Unveils New Generation of Dig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>JAY -- OTIS Federal Credit Union raised a tota...</td>\n",
       "      <td>6</td>\n",
       "      <td>https://www.centralmaine.com/2021/02/20/centra...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Central Maine business briefs: OTIS Federal Cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Students graduating from the fashion program a...</td>\n",
       "      <td>7</td>\n",
       "      <td>https://wwd.com/fashion-news/fashion-features/...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Otis College of Art and Design's Fashion Thesi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Today is Thursday, April 29, the 119th day of ...</td>\n",
       "      <td>8</td>\n",
       "      <td>https://santamariatimes.com/lifestyles/today-i...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Today in History: Aretha Franklin's cover of O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carré Otis wants justice, but she also wants c...</td>\n",
       "      <td>9</td>\n",
       "      <td>https://www.thedailybeast.com/supermodel-carre...</td>\n",
       "      <td>otis</td>\n",
       "      <td>Why Supermodel Carré Otis Is Taking on This To...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  article_id  \\\n",
       "0  Fracking machinery at a site operated by Range...           0   \n",
       "1  Good morning, and welcome to Otis's First Quar...           1   \n",
       "2  Good morning and welcome to Otis Fourth Quarte...           2   \n",
       "3  - Gen3 elevator adds built-in IoT benefits to ...           3   \n",
       "4  - Gen3 elevator adds built-in IoT benefits to ...           4   \n",
       "5  FARMINGTON, Conn., June 8, 2021 /PRNewswire/ -...           5   \n",
       "6  JAY -- OTIS Federal Credit Union raised a tota...           6   \n",
       "7  Students graduating from the fashion program a...           7   \n",
       "8  Today is Thursday, April 29, the 119th day of ...           8   \n",
       "9  Carré Otis wants justice, but she also wants c...           9   \n",
       "\n",
       "                                                 url company_name  \\\n",
       "0  https://triblive.com/opinion/joseph-otis-minot...         otis   \n",
       "1  https://www.fool.com/earnings/call-transcripts...         otis   \n",
       "2  https://www.fool.com/earnings/call-transcripts...         otis   \n",
       "3  https://www.intellasia.net/%EF%BB%BFotis-unvei...         otis   \n",
       "4  https://www.intellasia.net/otis-unveils-new-ge...         otis   \n",
       "5  https://www.marketscreener.com//quote/stock/OT...         otis   \n",
       "6  https://www.centralmaine.com/2021/02/20/centra...         otis   \n",
       "7  https://wwd.com/fashion-news/fashion-features/...         otis   \n",
       "8  https://santamariatimes.com/lifestyles/today-i...         otis   \n",
       "9  https://www.thedailybeast.com/supermodel-carre...         otis   \n",
       "\n",
       "                                               title  \n",
       "0  Joseph Otis Minott: Biden must prioritize heal...  \n",
       "1  OTIS WORLDWIDE CORP (OTIS) Q1 2021 Earnings Ca...  \n",
       "2  OTIS WORLDWIDE CORP (OTIS) Q4 2020 Earnings Ca...  \n",
       "3  ﻿ Otis Unveils New Generation of Digitally Nat...  \n",
       "4  Otis Unveils New Generation of Digitally Nativ...  \n",
       "5  Otis Worldwide : Unveils New Generation of Dig...  \n",
       "6  Central Maine business briefs: OTIS Federal Cr...  \n",
       "7  Otis College of Art and Design's Fashion Thesi...  \n",
       "8  Today in History: Aretha Franklin's cover of O...  \n",
       "9  Why Supermodel Carré Otis Is Taking on This To...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_list = []\n",
    "grouped_df = snippet_df.groupby(['article_id'])\n",
    "for name,group in grouped_df:\n",
    "    temp_dict = dict()\n",
    "    text = \"\\n\".join(list(group.text))\n",
    "    temp_dict['text'] = text\n",
    "    temp_dict['article_id'] = group.iloc[0].article_id\n",
    "    temp_dict['url'] = group.iloc[0].url\n",
    "    temp_dict['company_name'] = group.iloc[0].company_name\n",
    "    temp_dict['title'] = group.iloc[0].title\n",
    "    ind_list.append(temp_dict)\n",
    "drop_dup_df=pd.DataFrame(ind_list)\n",
    "drop_dup_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_dup_df.to_csv('data_bytitle_V2_after_DupRem_NLTK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def get_cleaned_text(text):\n",
    "    text = re.sub(\"\\(.*?\\)\", '', text)\n",
    "    text = re.sub(\"\\[.*?\\]\", '', text)\n",
    "    text = re.sub('\\*', '', text)\n",
    "    text = re.sub('\\s\\s+', ' ', text)\n",
    "    text = re.sub('\\.\\s\\.', '.', text)\n",
    "    text = re.sub(',\\s,', ',', text)\n",
    "    text = re.sub(';\\s;', ';', text)\n",
    "    text = re.sub(':\\s:', ':', text)\n",
    "    text = re.sub('\\?\\s\\?', '?', text)\n",
    "    text = re.sub('\\!\\s\\!', '!', text)\n",
    "    return text.strip()\n",
    "\n",
    "def get_sents_for_doc(text):\n",
    "    text = get_cleaned_text(text)\n",
    "    #doc = nlp_spacy(text)\n",
    "    #sents = list(doc.sents)\n",
    "    sents = nltk.tokenize.sent_tokenize(str(text))\n",
    "    len_sents = len(sents)\n",
    "    final_2sents_list = []\n",
    "    for i in range(1, len_sents):\n",
    "        temp_text = sents[i-1] + ' ' + sents[i]\n",
    "        temp_text = re.sub('\"', '', temp_text)\n",
    "        final_2sents_list.append(temp_text.strip())\n",
    "    return final_2sents_list\n",
    "\n",
    "def map_snippets_art(row):\n",
    "    body = row['text']\n",
    "    snippets = get_sents_for_doc(body)\n",
    "    final_snippend_list = []\n",
    "    for snip in snippets:\n",
    "        temp_dict = dict()\n",
    "        temp_dict['text'] = snip\n",
    "        temp_dict['article_id'] = row['article_id']\n",
    "        temp_dict['url'] = row['url']\n",
    "        temp_dict['company_name'] = row['company_name']\n",
    "        temp_dict['title'] = row['title']\n",
    "        final_snippend_list.append(temp_dict)\n",
    "    return final_snippend_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippets_list = []\n",
    "lst=[]\n",
    "for idx, row in drop_dup_df.iterrows():\n",
    "    lst.append(idx)\n",
    "    one_snippet_list = map_snippets_art(row)\n",
    "    snippets_list.extend(one_snippet_list)\n",
    "snippet_df = pd.DataFrame(snippets_list)\n",
    "snippet_df['id'] = range(0, len(snippet_df))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_df.to_csv('snippet_bytitle_V2_after_DupRem_NLTK.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id\n",
    "0\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "26\n",
    "27\n",
    "28\n",
    "29\n",
    "30\n",
    "31\n",
    "32\n",
    "33\n",
    "34\n",
    "0\n",
    "1\n",
    "2\n",
    "3\n",
    "4\n",
    "5\n",
    "6\n",
    "7\n",
    "8\n",
    "9\n",
    "10\n",
    "11\n",
    "12\n",
    "13\n",
    "14\n",
    "15\n",
    "16\n",
    "17\n",
    "18\n",
    "19\n",
    "20\n",
    "21\n",
    "22\n",
    "23\n",
    "24\n",
    "25\n",
    "26\n",
    "27\n",
    "28\n",
    "29\n",
    "30\n",
    "31\n",
    "32\n",
    "33\n",
    "34\n",
    "35\n",
    "36\n",
    "37\n",
    "38\n",
    "39\n",
    "40\n",
    "41\n",
    "42\n",
    "43\n",
    "44\n",
    "45\n",
    "46\n",
    "47\n",
    "48\n",
    "49\n",
    "50\n",
    "51\n",
    "52\n",
    "53\n",
    "54\n",
    "55\n",
    "56\n",
    "57\n",
    "58\n",
    "59\n",
    "60\n",
    "61\n",
    "62\n",
    "63\n",
    "64\n",
    "65\n",
    "66\n",
    "67\n",
    "68\n",
    "69\n",
    "70\n",
    "71\n",
    "72\n",
    "73\n",
    "74\n",
    "75\n",
    "76\n",
    "77\n",
    "78\n",
    "79\n",
    "80\n",
    "81\n",
    "82\n",
    "83\n",
    "84\n",
    "85\n",
    "86\n",
    "87\n",
    "88\n",
    "89\n",
    "90\n",
    "91\n",
    "92\n",
    "93\n",
    "94\n",
    "95\n",
    "96\n",
    "97\n",
    "98\n",
    "99\n",
    "100\n",
    "101\n",
    "102\n",
    "103\n",
    "104\n",
    "105\n",
    "106\n",
    "107\n",
    "108\n",
    "109\n",
    "110\n",
    "111\n",
    "112\n",
    "113\n",
    "114\n",
    "115\n",
    "116\n",
    "117\n",
    "118\n",
    "119\n",
    "120\n",
    "121\n",
    "122\n",
    "123\n",
    "124\n",
    "125\n",
    "126\n",
    "127\n",
    "128\n",
    "129\n",
    "130\n",
    "131\n",
    "132\n",
    "133\n",
    "134\n",
    "135\n",
    "136\n",
    "137\n",
    "138\n",
    "139\n",
    "140\n",
    "141\n",
    "142\n",
    "143\n",
    "144\n",
    "145\n",
    "146\n",
    "147\n",
    "148\n",
    "149\n",
    "150\n",
    "151\n",
    "152\n",
    "153\n",
    "154\n",
    "155\n",
    "156\n",
    "157\n",
    "158\n",
    "159\n",
    "160\n",
    "161\n",
    "162\n",
    "163\n",
    "164\n",
    "165\n",
    "166\n",
    "167\n",
    "168\n",
    "169\n",
    "170\n",
    "171\n",
    "172\n",
    "173\n",
    "174\n",
    "175\n",
    "176\n",
    "177\n",
    "178\n",
    "179\n",
    "181\n",
    "182\n",
    "183\n",
    "184\n",
    "185\n",
    "186\n",
    "187\n",
    "188\n",
    "190\n",
    "191\n",
    "192\n",
    "193\n",
    "194\n",
    "195\n",
    "196\n",
    "197\n",
    "198\n",
    "199\n",
    "200\n",
    "201\n",
    "202\n",
    "203\n",
    "204\n",
    "205\n",
    "206\n",
    "207\n",
    "208\n",
    "209\n",
    "210\n",
    "211\n",
    "212\n",
    "213\n",
    "214\n",
    "215\n",
    "216\n",
    "217\n",
    "218\n",
    "219\n",
    "220\n",
    "221\n",
    "222\n",
    "223\n",
    "224\n",
    "225\n",
    "226\n",
    "227\n",
    "228\n",
    "229\n",
    "230\n",
    "231\n",
    "232\n",
    "233\n",
    "234\n",
    "235\n",
    "236\n",
    "237\n",
    "238\n",
    "239\n",
    "240\n",
    "241\n",
    "242\n",
    "243\n",
    "244\n",
    "245\n",
    "246\n",
    "247\n",
    "248\n",
    "249\n",
    "250\n",
    "251\n",
    "252\n",
    "254\n",
    "255\n",
    "256\n",
    "257\n",
    "258\n",
    "259\n",
    "260\n",
    "261\n",
    "262\n",
    "263\n",
    "264\n",
    "265\n",
    "266\n",
    "267\n",
    "268\n",
    "269\n",
    "270\n",
    "271\n",
    "272\n",
    "273\n",
    "274\n",
    "275\n",
    "276\n",
    "277\n",
    "278\n",
    "279\n",
    "280\n",
    "281\n",
    "282\n",
    "283\n",
    "284\n",
    "285\n",
    "286\n",
    "287\n",
    "288\n",
    "289\n",
    "290\n",
    "291\n",
    "292\n",
    "293\n",
    "294\n",
    "295\n",
    "296\n",
    "297\n",
    "298\n",
    "299\n",
    "300\n",
    "301\n",
    "302\n",
    "303\n",
    "304\n",
    "305\n",
    "306\n",
    "307\n",
    "308\n",
    "309\n",
    "310\n",
    "311\n",
    "312\n",
    "313\n",
    "314\n",
    "315\n",
    "316\n",
    "317\n",
    "318\n",
    "319\n",
    "320\n",
    "321\n",
    "322\n",
    "323\n",
    "324\n",
    "325\n",
    "326\n",
    "327\n",
    "328\n",
    "329\n",
    "330\n",
    "331\n",
    "332\n",
    "333\n",
    "334\n",
    "335\n",
    "336\n",
    "337\n",
    "338\n",
    "339\n",
    "340\n",
    "341\n",
    "342\n",
    "343\n",
    "344\n",
    "345\n",
    "346\n",
    "347\n",
    "348\n",
    "349\n",
    "350\n",
    "351\n",
    "352\n",
    "353\n",
    "354\n",
    "355\n",
    "356\n",
    "357\n",
    "358\n",
    "359\n",
    "360\n",
    "361\n",
    "362\n",
    "363\n",
    "364\n",
    "365\n",
    "366\n",
    "367\n",
    "368\n",
    "369\n",
    "370\n",
    "371\n",
    "372\n",
    "373\n",
    "374\n",
    "375\n",
    "376\n",
    "377\n",
    "378\n",
    "380\n",
    "381\n",
    "382\n",
    "383\n",
    "384\n",
    "385\n",
    "386\n",
    "387\n",
    "388\n",
    "389\n",
    "390\n",
    "391\n",
    "392\n",
    "393\n",
    "394\n",
    "395\n",
    "396\n",
    "397\n",
    "398\n",
    "399\n",
    "400\n",
    "401\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
